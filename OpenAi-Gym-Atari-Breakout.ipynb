{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee73b59",
   "metadata": {},
   "source": [
    "# OpenAI Gym\n",
    "[Gym](https://www.gymlibrary.dev/) is an open-source Python library, made for the easy development and testing of reinforcement learning algorithms. Today we will use it to create and run an instance of the Atari game Breakout. The Gym library provies us access to the game state, game rewards, and available actions, which if you remember are nesseicary parts of our RL framework. \n",
    "\n",
    "<img src=\"Test.gif\" width=\"200\" align=\"center\">\n",
    "\n",
    "### The RL Framework for Breakout:\n",
    "- **Action:** Move the paddle left and right \n",
    "- **State:** The 210x160 RGB image frame \n",
    "- **Reward:** Amount the game score increases \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8773c08b",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf8785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import cv2\n",
    "import time \n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c0730",
   "metadata": {},
   "source": [
    "We need to set the environment variable ALE_PY_ROM_DIR to the directory of the bins so that we can use the namespace ALE/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b10f116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.0+919230b)\n",
      "[Powered by Stella]\n",
      "Game console created:\n",
      "  ROM file:  /Users/justinvalentine/opt/anaconda3/envs/Test/lib/python3.9/site-packages/ale_py/roms/breakout.bin\n",
      "  Cart Name: Breakout - Breakaway IV (1978) (Atari)\n",
      "  Cart MD5:  f34f08e5eb96e500e851a80be3277a56\n",
      "  Display Format:  AUTO-DETECT ==> NTSC\n",
      "  ROM Size:        2048\n",
      "  Bankswitch Type: AUTO-DETECT ==> 2K\n",
      "\n",
      "Running ROM file...\n",
      "Random seed is 1667373141\n"
     ]
    }
   ],
   "source": [
    "from ale_py import ALEInterface\n",
    "ale = ALEInterface()\n",
    "\n",
    "from ale_py.roms import Breakout\n",
    "ale.loadROM(Breakout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274b2496",
   "metadata": {},
   "source": [
    "## Creating the Atari Breakout Instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01518217",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"ALE/Breakout-v5\") # creats a game instance of Atari Breakout \n",
    "\n",
    "env.reset()\n",
    "image_lst = []\n",
    "\n",
    "step_num, total_reward = 0, 0\n",
    "\n",
    "while step_num < 100:\n",
    "    # Used to generates random actions\n",
    "    action = env.env.action_space.sample()\n",
    "    \n",
    "    # Get the next state, and reward after taking your action \n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # Create image frame \n",
    "    img = cv2.resize(state, (160, 210), interpolation=cv2.INTER_CUBIC)\n",
    "    frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    image_lst.append(frame)\n",
    "        \n",
    "    time.sleep(0.01)\n",
    "    step_num += 1\n",
    "\n",
    "env.close()\n",
    "\n",
    "imageio.mimsave('random-action.gif', image_lst, fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346a9b63",
   "metadata": {},
   "source": [
    "<img src=\"random-action.gif\" width=\"300\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9943f27",
   "metadata": {},
   "source": [
    "## Applying Reinforcement Learning to Breakout \n",
    "Recall that the main idea of Reinforcemnt Learnign is for our Agent to select the best action at each time step given its current state at that time step. When we say 'best action' we mean that the agent is making the action with the goal of maximising total reward.  \n",
    "\n",
    "However it is not enough for the agent to just select the greedy action at every time-step, the agent must also explore its other options. The agent then 'learns' what actions are good in what states, and 'remembers' these resutls. \n",
    "\n",
    "So how can we train the Agent to play like a human, when all the agent can do interact whith the game and see how it affects the pixels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0245f8",
   "metadata": {},
   "source": [
    "### The Challenges\n",
    "The first challenge we need to addres is that each state of the game contains alot of information! \n",
    "In this case, if we have a video game with a 640x480 resolution, the current state of a game frame will be encoded by 640x480=307200 pixels values, and the number of possible state variations will be enormous"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5511c47aec90ff6d3bf2282aa911cd8b4e17a7dd8b958807807acb2e44bc0528"
  },
  "kernelspec": {
   "display_name": "Test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
